[DEFAULT]
debug = true
flow_definition = './flow_definition.yaml'
nats_uri = 'nats://nats:4222'
capnp_schema = './schema.capnp'

[ingestor]
datasource = zmq:zmq_ingestor
processor = nprobe
processes = 1

#[nsq_ingestor]
#lookupd_http_addresses = [http://nsq-lookupd:4161]
#topic = vflow.netflow9
#channel = "minerwa#ephemeral"
#max_in_flight = 2500

[zmq_ingestor]
publisher_uri = "tcp://host.docker.internal:5556"

[detector]
detectors = [ai:ai_detector]

[ai_detector]
# detector process count - must be at least 2 (one ingesting, one analyzing)
processes = 2

# time span of window in seconds
#window_size = 2
window_size = 1000

# minimum number of entries per window
#win_min_entries = 2

# minimum number of windows to compute statistics upon
#win_min_cnt = 5

# maximum number of windows to summarize
#win_max_cnt = 200

# number of windows for window timeouting
#win_timeout = 700

# maximum length for flows spanning multiple windows to consider in inter-flow times computation
#flow_winspan_max_len = 2000

# number of flows to be cached and analyzed in single batch
#flow_cache_size = 5000
flow_cache_size = 200

# number of samples for port entropy computation
#samples_cnt = 30

# memory to be used by Spark (in gigabytes)
#spark_memory = 50
spark_memory = 1

# number of parallel jobs for parallel parts of analysis
#parallel_jobs = 1

# base directory for temporary files
#temp_dir = "/tmp"

# path to scaling config
#scaling_config_path = "/etc/minerwa/scaling_config.yaml"

# path to binary classification-based filter model
#binary_model_path = "/etc/minerwa/binary_filter_model.pkl"

# malignity threshold for binary classification
#binary_model_threshold = 0.75

# path to multiclass classification-based filter model
#class_model_path = "/etc/minerwa/class_filter_model.pkl"

# malignity threshold for multiclass classification
#class_model_threshold = 0.5

# path to VAE (AI) model
#vae_model_path = "/etc/minerwa/vae_model"

# anomaly threshold for VAE (AI) detection
#vae_model_threshold = 0.15

# device used by PyTorch - values can be:
# - "cpu" (no GPU acceleration)
# - "cuda" (uses one of available graphic cards)
# - "cuda:x" (where x is comma-separated list of card ids - e.g. "cuda:0", "cuda:0,1", etc.)
#torch_device = "cpu"
